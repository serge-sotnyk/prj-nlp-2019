{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_path = './SemEval-PIT2015-py3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tags(string):\n",
    "    return [tuple(i.split(\"/\")) for i in string.split()]\n",
    "\n",
    "def readTrainData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = eval(judge)[0]            \n",
    "        if nYes >= 3:\n",
    "            amt_label = True\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "        elif nYes <= 1:\n",
    "            amt_label = False\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "    return data\n",
    "\n",
    "def readTestData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = int(judge[0])\n",
    "        if nYes >= 4:\n",
    "            expert_label = True\n",
    "        elif nYes <= 2:\n",
    "            expert_label = False\n",
    "        else:\n",
    "            expert_label = None\n",
    "        if expert_label != None:\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), expert_label))\n",
    "    return data\n",
    "\n",
    "train_data = readTrainData(\"SemEval-PIT2015-py3/data/dev.data\")\n",
    "test_data = readTestData(\"SemEval-PIT2015-py3/data/test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('All', 'O', 'DT', 'B-NP', 'O'),\n",
       "  ('the', 'O', 'DT', 'I-NP', 'O'),\n",
       "  ('home', 'O', 'NN', 'I-NP', 'O'),\n",
       "  ('alones', 'O', 'VBZ', 'B-VP', 'O'),\n",
       "  ('watching', 'O', 'VBG', 'I-VP', 'B-EVENT'),\n",
       "  ('8', 'O', 'CD', 'B-NP', 'O'),\n",
       "  ('mile', 'O', 'NN', 'I-NP', 'O')],\n",
       " [('The', 'O', 'DT', 'B-NP', 'O'),\n",
       "  ('last', 'O', 'JJ', 'I-NP', 'O'),\n",
       "  ('rap', 'O', 'NN', 'I-NP', 'B-EVENT'),\n",
       "  ('battle', 'O', 'NN', 'I-NP', 'B-EVENT'),\n",
       "  ('in', 'O', 'IN', 'B-PP', 'O'),\n",
       "  ('8', 'O', 'CD', 'B-NP', 'O'),\n",
       "  ('Mile', 'O', 'NNP', 'I-NP', 'O'),\n",
       "  ('nevr', 'O', 'NN', 'I-NP', 'O'),\n",
       "  ('gets', 'O', 'VBZ', 'B-VP', 'O'),\n",
       "  ('old', 'O', 'JJ', 'B-NP', 'O'),\n",
       "  ('ahah', 'O', 'JJ', 'I-NP', 'O')],\n",
       " False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_cache = {}\n",
    "def get_wordnet_features(tweet):\n",
    "    feature_set = set()\n",
    "\n",
    "    for item in tweet:\n",
    "        word = item[0].lower()\n",
    "        if word not in stop_words:\n",
    "            if word in wordnet_cache:\n",
    "                feature_set.update(wordnet_cache[word])\n",
    "            else:\n",
    "                temp_features = set()\n",
    "                syns = wordnet.synsets(word)\n",
    "                for syn in syns[:4]:\n",
    "                    temp_features.update(syn.lemma_names())\n",
    "#                     for hyp in syn.hypernyms():\n",
    "#                         temp_features.update(hyp.lemma_names())\n",
    "                wordnet_cache[word] = temp_features\n",
    "                feature_set.update(temp_features)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec_similarity(tweet1, tweet2):\n",
    "    tokens_1 = [] \n",
    "    tokens_2 = [] \n",
    "    for w in tweet1:\n",
    "        word = w[0].lower()\n",
    "        if word not in stop_words:\n",
    "            tokens_1.append(word)\n",
    "    \n",
    "    for w in tweet2:\n",
    "        word = w[0].lower()\n",
    "        if word not in stop_words:\n",
    "            tokens_2.append(word)\n",
    "    distance = model.wmdistance(tokens_1, tokens_2)\n",
    "    if distance == float(\"inf\"):\n",
    "        return 0.0\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    features, labels = [], []\n",
    "    for tweet in data:\n",
    "        feature = {}\n",
    "        tweet1, tweet2, areSimilar = tweet\n",
    "        feature['sim'] = len(get_wordnet_features(tweet1) & get_wordnet_features(tweet2))\n",
    "        feature['vec_sim'] = get_vec_similarity(tweet1, tweet2)\n",
    "        features.append(feature)\n",
    "        labels.append(areSimilar)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = extract_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = extract_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('logistregress', LogisticRegression(solver='sag')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(semeval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tKOSTROV\t05_SYNONYMS\t\tF: 0.516\tPrec: 0.565\tRec: 0.474\t\tP-corr: -0.095\tF1: 0.346\tPrec: 0.209\tRec: 1.000\r\n"
     ]
    }
   ],
   "source": [
    "filename_s = 'systemoutputs/PIT2015_KOSTROV_05_SYNONYMS.output'\n",
    "clf.fit(x_train, y_train)\n",
    "predicted_probability = clf.predict_proba(x_test)\n",
    "output = [(prob_true > prob_false, prob_true if prob_true > prob_false else prob_false) for [prob_false, prob_true] in predicted_probability]\n",
    "with open(filename_s , 'a+') as f:\n",
    "    f.truncate(0)\n",
    "    for line in output:\n",
    "        f.write(str(line[0]).lower() + '\\t' + str(line[1]) + '\\n')\n",
    "!python scripts/pit2015_eval_single.py data/test.label $filename_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms + hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tKOSTROV\t05_HYPERNYMS\t\tF: 0.478\tPrec: 0.483\tRec: 0.474\t\tP-corr: -0.044\tF1: 0.348\tPrec: 0.213\tRec: 0.949\r\n"
     ]
    }
   ],
   "source": [
    "filename_s = 'systemoutputs/PIT2015_KOSTROV_05_HYPERNYMS.output'\n",
    "clf.fit(x_train, y_train)\n",
    "predicted_probability = clf.predict_proba(x_test)\n",
    "output = [(prob_true > prob_false, prob_true if prob_true > prob_false else prob_false) for [prob_false, prob_true] in predicted_probability]\n",
    "with open(filename_s , 'a+') as f:\n",
    "    f.truncate(0)\n",
    "    for line in output:\n",
    "        f.write(str(line[0]).lower() + '\\t' + str(line[1]) + '\\n')\n",
    "!python scripts/pit2015_eval_single.py data/test.label $filename_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms + vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tKOSTROV\t05_VECTOR\t\tF: 0.514\tPrec: 0.579\tRec: 0.463\t\tP-corr: -0.100\tF1: 0.347\tPrec: 0.210\tRec: 0.994\r\n"
     ]
    }
   ],
   "source": [
    "filename_s = 'systemoutputs/PIT2015_KOSTROV_05_VECTOR.output'\n",
    "clf.fit(x_train, y_train)\n",
    "predicted_probability = clf.predict_proba(x_test)\n",
    "output = [(prob_true > prob_false, prob_true if prob_true > prob_false else prob_false) for [prob_false, prob_true] in predicted_probability]\n",
    "with open(filename_s , 'a+') as f:\n",
    "    f.truncate(0)\n",
    "    for line in output:\n",
    "        f.write(str(line[0]).lower() + '\\t' + str(line[1]) + '\\n')\n",
    "!python scripts/pit2015_eval_single.py data/test.label $filename_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
