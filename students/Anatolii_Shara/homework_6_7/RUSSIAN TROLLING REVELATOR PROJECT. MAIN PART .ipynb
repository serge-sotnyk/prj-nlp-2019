{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = Path('D:/junta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = list()\n",
    "with data_file.open('r') as f:\n",
    "    comments = f.read()\n",
    "    for i, line in enumerate(comments.split('\\n')):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            line = line.replace('п»ї', ' ')\n",
    "            try:\n",
    "                label, author, text = line.split('|')\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "                print(f'Line number {i}')\n",
    "                print(line, '\\n')\n",
    "            else:\n",
    "                label = label.strip()\n",
    "                author = author.strip()\n",
    "                text = text.strip()\n",
    "                if label in ('neutral', 'trolling'):\n",
    "                    temp_data.append(dict(label=label, author=author, text=text))\n",
    "                else:\n",
    "                    print('BAD LABEL')\n",
    "                    print(f'Line number {i}')\n",
    "                    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrame:\n",
    "    def __init__(self, comments):\n",
    "        self.comments = comments\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for x in self.comments:\n",
    "            yield x\n",
    "        \n",
    "    def _field_by_name(self, name):\n",
    "        return [x[name] for x in self]\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._field_by_name('label')\n",
    "    \n",
    "    @property\n",
    "    def authors(self):\n",
    "        return self._field_by_name('author')\n",
    "    \n",
    "    @property\n",
    "    def texts(self):\n",
    "        return self._field_by_name('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Piscator76', 19),\n",
       " ('Berlino10', 18),\n",
       " ('Stetschkin', 16),\n",
       " ('Fremdhier', 15),\n",
       " ('Mandalore', 14),\n",
       " ('Pippin', 11),\n",
       " ('faktenfaktenfakten', 10),\n",
       " ('Waltraud Gundlach', 10),\n",
       " ('Heekhof', 9),\n",
       " ('Reverend Wicks Cherrycoke', 9)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "author_counter = Counter(df.authors)\n",
    "author_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(df.texts, df.labels, test_size=0.3, \n",
    "                                                                  stratify=df.labels, shuffle=True,\n",
    "                                                                  random_state=42)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df.labels)\n",
    "\n",
    "label_train = le.transform(label_train)\n",
    "label_test = le.transform(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, texts, y=None):\n",
    "        texts = [self.transform_one(t) for t in texts]\n",
    "        return texts\n",
    "    \n",
    "    def transform_one(self, text):\n",
    "        text = text.lower()\n",
    "        text = self.replace_numbers(text)\n",
    "        return text\n",
    "    \n",
    "    def replace_numbers(self, text):\n",
    "        return re.sub(r'\\d+', '000', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def my_tokenize(text):\n",
    "    return re.split(r'[^\\p{L}]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipe = Pipeline([\n",
    "    ('cleaning', TextCleaner()),\n",
    "    ('counts', TfidfVectorizer(tokenizer=my_tokenize, stop_words=stopwords.words('german'))),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('features', features_pipe),\n",
    "    ('nb', LogisticRegression()),\n",
    "])\n",
    "\n",
    "hyper = {\n",
    "    'features__counts__analyzer': ['word'],\n",
    "    'features__counts__ngram_range': [(1, 1), (1, 2), (1, 3), (3, 4), (3, 5), (4, 5), (4, 6)],\n",
    "    'nb__C': [0.1, 1.0, 10],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipe, hyper, scoring='f1', cv=3, refit=True, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.759145935469\n",
      "Best Params {'features__counts__analyzer': 'word', 'features__counts__ngram_range': (1, 3), 'nb__C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashara\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(data_train, label_train)\n",
    "\n",
    "print('Best Score', clf.best_score_)\n",
    "print('Best Params', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.41      0.53       147\n",
      "           1       0.67      0.90      0.77       195\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       342\n",
      "   macro avg       0.71      0.66      0.65       342\n",
      "weighted avg       0.71      0.69      0.67       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true=label_test, y_pred=predict_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = clf.best_estimator_.__dict__['steps'][1][1].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = clf.best_estimator_.__dict__['steps'][0][1].__dict__['steps'][1][1].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_weights = sorted(zip(ngrams, weights), key=lambda x: -abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                krim : 5.38\n",
      "             ukraine : 3.33\n",
      "                nato : 2.91\n",
      "             artikel : -2.91\n",
      "            russland : 2.83\n",
      "                kiew : 2.42\n",
      "              westen : 2.28\n",
      "                  eu : 2.07\n",
      "               danke : -1.94\n",
      "              kosovo : 1.87\n",
      "              russen : 1.79\n",
      "          sanktionen : 1.69\n",
      "              putsch : 1.67\n",
      "       demonstranten : 1.57\n",
      "            annexion : 1.56\n",
      "           regierung : 1.56\n",
      "          faschisten : 1.52\n",
      "         deutschland : -1.49\n",
      "              durfte : 1.38\n",
      "                 usa : 1.37\n"
     ]
    }
   ],
   "source": [
    "for ng, w in ngrams_weights[:20]:\n",
    "    print(f'{ng:>20} : {w:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
